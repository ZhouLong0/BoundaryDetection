{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f235eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring unknown arguments: ['-f', '/leonardo/home/userexternal/lzhou001/.local/share/jupyter/runtime/kernel-c2cfe7fd-b3af-4193-a88c-9f5c7557a978.json']\n",
      "Offline mode forced. Seed set to 42. Dataset=egoper. Method=bsurprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/leonardo/home/userexternal/lzhou001/miniconda3/envs/EfficientGEBD/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/leonardo/home/userexternal/lzhou001/miniconda3/envs/EfficientGEBD/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Qwen3VL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/leonardo/home/userexternal/lzhou001/miniconda3/envs/EfficientGEBD/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:2284: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████| 4/4 [00:42<00:00, 10.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing EgoperDataset for recipe: quesadilla...\n",
      "Saved run configuration to results/bsurprise/egoper/20260225_142732/run_config.json\n",
      "Experiment configuration:\n",
      "  exp_id: 20260225_142732\n",
      "  dataset: egoper\n",
      "  method: bsurprise\n",
      "  recipe: quesadilla\n",
      "  seed: 42\n",
      "  threshold: 0.3\n",
      "  base_dir: data/Egoper/extracted_frames\n",
      "  split_name: test.split1.bundle\n",
      "  split_files: test.split1.bundle\n",
      "  chunk_duration: 2.0\n",
      "  prompt_file: None\n",
      "  prompt_set_idx: None\n",
      "  baseline_prompt_set: None\n",
      "  egoper_config: {'max_new_tokens': 500, 'n_hypotheses': 5, 'GEN_PROMPT_TEMPLATE': 'Context so far in this first view video: {memory_text}\\nBased on this information and recent frames, predict {n} plausible next events that are semantically different from the current action. Each event should be in 8-10 words. Each event should be separated with linebreak. Focus on the main action.', 'VERIFY_PROMPT_TEMPLATE': \"Statement: {hypothesis}\\nIs this statement true in the CURRENT video? Answer only with 'yes' or 'no'.\", 'DESCR_PROMPT_TEMPLATE': 'The video shows the first view of a person performing an action. Describe the action being performed by the person in 8-10 words in this 2 second video segment.Describe only what is directly observable in the video.', 'TOKEN_YES': 'yes', 'TOKEN_NO': 'no', 'SPLIT_TOKEN': 'assistant\\n', 'VERIFY_PROMPT_TEMPLATE_W_HISTORY': 'You are given a textual summary of the video so far, the hypothesis of what is happening and the current video. Your task is to evaluate whether each hypothesis generated from the prior context holds in the current video.Context so far: {memory_text}Hypothesis: {hypothesis}Question: Is this hypothesis true in the current video? Answer with a single word: yes or no.', 'MATCH_PROMPT_TEMPLATE': '\\n        Task: choose exactly one step index for the event description.\\n\\n        You are given:\\n        - A numbered list of recipe steps.\\n        - One event description from a video.\\n\\n        Rules:\\n        1) Return the index of the BEST matching step.\\n        2) If no step clearly matches, return the Background index.\\n        3) Match by action semantics, not exact wording.\\n        4) Ignore minor object/detail errors if the core action matches.\\n        5) If unsure between multiple steps, choose the closest action in time/order.\\n\\n        Recipe steps:\\n        {steps_block}\\n\\n        Background index: {bg_idx}\\n\\n        Event description:\\n        {description}\\n\\n        Output format:\\n        Return ONLY one integer (example: 3). No words, no punctuation.\\n        '}\n",
      "  history_conditioning: True\n",
      "  full_steps: False\n",
      "\n",
      "\n",
      "Processing quesadilla_u1_a2_normal_006...\n",
      "Running history-conditioned classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Asked to sample `fps` frames per second but no video metadata was provided which is required when sampling with `fps`. Defaulting to `fps=24`. Please provide `video_metadata` for more accurate results.\n"
     ]
    }
   ],
   "source": [
    "from importlib import import_module\n",
    "import sys\n",
    "\n",
    "# Import the module and run its main function\n",
    "module = import_module('01_bsurprise_egoper')\n",
    "module.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc9b60b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
