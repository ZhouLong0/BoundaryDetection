{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd48f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load dependencies and define utilities\n",
    "\n",
    "import mediapy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def read_and_preprocess_video(\n",
    "    filename: str, target_num_frames: int, target_frame_size: tuple[int, int]\n",
    "):\n",
    "  \"\"\"Reads and preprocesses a video.\"\"\"\n",
    "\n",
    "  frames = mediapy.read_video(filename)\n",
    "\n",
    "  # Sample to target number of frames.\n",
    "  frame_indices = np.linspace(\n",
    "      0, len(frames), num=target_num_frames, endpoint=False, dtype=np.int32\n",
    "  )\n",
    "  frames = np.asarray([frames[i] for i in frame_indices])\n",
    "\n",
    "  # Resize to target size.\n",
    "  original_height, original_width = frames.shape[-3:-1]\n",
    "  target_height, target_width = target_frame_size\n",
    "  assert (\n",
    "      original_height * target_width == original_width * target_height\n",
    "  ), 'Currently does not support aspect ratio mismatch.'\n",
    "  frames = mediapy.resize_video(frames, shape=target_frame_size)\n",
    "\n",
    "  # Normalize pixel values to [0.0, 1.0].\n",
    "  frames = mediapy.to_float01(frames)\n",
    "\n",
    "  return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import mediapy\n",
    "from PIL import Image\n",
    "\n",
    "def read_and_preprocess_frames_from_folder(\n",
    "    folder_path: str, \n",
    "    target_num_frames: int, \n",
    "    target_frame_size: tuple[int, int] = (288, 288), \n",
    "    overlap: float = 0.0\n",
    "):\n",
    "  \"\"\"\n",
    "  Reads images from a folder, resizes them, and splits them into batches with optional overlap.\n",
    "  \n",
    "  Args:\n",
    "      folder_path (str): Path to folder containing image sequences.\n",
    "      target_num_frames (int): Number of frames per batch.\n",
    "      target_frame_size (tuple): (height, width) for resizing. Defaults to (288, 288).\n",
    "      overlap (float): Fraction of overlap between batches [0.0, 1.0). \n",
    "                       0.0 = distinct batches, 0.5 = 50% overlap.\n",
    "  \n",
    "  Returns:\n",
    "      np.ndarray: A numpy array of shape (num_batches, target_num_frames, H, W, 3).\n",
    "  \"\"\"\n",
    "  \n",
    "  # Validate overlap\n",
    "  if not (0.0 <= overlap < 1.0):\n",
    "      raise ValueError(\"Overlap must be >= 0.0 and < 1.0\")\n",
    "\n",
    "  # 1. Find all image files\n",
    "  extensions = ['*.jpg', '*.jpeg', '*.png']\n",
    "  image_paths = []\n",
    "  \n",
    "  for ext in extensions:\n",
    "      image_paths.extend(glob.glob(os.path.join(folder_path, ext)))\n",
    "  \n",
    "  # 2. Sort naturally to ensure temporal order\n",
    "  image_paths.sort()\n",
    "\n",
    "  if not image_paths:\n",
    "      print(f\"[WARN] No images found in {folder_path}\")\n",
    "      return np.array([])\n",
    "      \n",
    "  if len(image_paths) < target_num_frames:\n",
    "      print(f\"[WARN] Found {len(image_paths)} frames, but need {target_num_frames} for a batch.\")\n",
    "      return np.array([])\n",
    "\n",
    "  print(f\"Folder: {os.path.basename(folder_path)} | Loading {len(image_paths)} frames...\")\n",
    "\n",
    "  # 3. Load and Resize ALL frames into a continuous buffer\n",
    "  buffer_frames = []\n",
    "  target_height, target_width = target_frame_size\n",
    "\n",
    "  for path in image_paths:\n",
    "      try:\n",
    "          img = Image.open(path).convert(\"RGB\")\n",
    "          img = img.resize((target_width, target_height), Image.Resampling.BILINEAR)\n",
    "          buffer_frames.append(np.array(img))\n",
    "      except Exception as e:\n",
    "          print(f\"[ERROR] Could not load {path}: {e}\")\n",
    "\n",
    "  buffer_frames = np.array(buffer_frames) # Shape: (Total_Frames, H, W, 3)\n",
    "\n",
    "  # 4. Create Batches using Sliding Window\n",
    "  stride = int(target_num_frames * (1 - overlap))\n",
    "  stride = max(1, stride) # Prevent infinite loop if overlap is high/frames low\n",
    "  \n",
    "  batched_frames = []\n",
    "  num_frames = len(buffer_frames)\n",
    "  \n",
    "  for start_idx in range(0, num_frames, stride):\n",
    "      end_idx = start_idx + target_num_frames\n",
    "      \n",
    "      if end_idx > num_frames:\n",
    "          break\n",
    "          \n",
    "      batch = buffer_frames[start_idx:end_idx]\n",
    "      batched_frames.append(batch)\n",
    "\n",
    "  if not batched_frames:\n",
    "      return np.array([])\n",
    "\n",
    "  # Stack into final shape: (Num_Batches, Sequence_Length, H, W, C)\n",
    "  batched_frames = np.stack(batched_frames)\n",
    "\n",
    "  # 5. Normalize pixel values to [0.0, 1.0]\n",
    "  batched_frames = mediapy.to_float01(batched_frames)\n",
    "\n",
    "  print(f\"Generated {len(batched_frames)} batches with stride {stride}.\")\n",
    "  \n",
    "  return batched_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515cc2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load model\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from videoprism import models as vp\n",
    "\n",
    "MODEL_NAME = 'videoprism_public_v1_large'  # @param ['videoprism_public_v1_base', 'videoprism_public_v1_large'] {allow-input: false}\n",
    "USE_BFLOAT16 = False  # @param { type: \"boolean\" }\n",
    "NUM_FRAMES = 16\n",
    "FRAME_SIZE = 288\n",
    "\n",
    "fprop_dtype = jnp.bfloat16 if USE_BFLOAT16 else None\n",
    "flax_model = vp.get_model(MODEL_NAME, fprop_dtype=fprop_dtype)\n",
    "loaded_state = vp.load_pretrained_weights(MODEL_NAME)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def forward_fn(inputs, train=False):\n",
    "  return flax_model.apply(loaded_state, inputs, train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_FILE_PATH = 'videoprism_repo/videoprism/assets/water_bottle_drumming.mp4'  # @param {type: \"string\"}\n",
    "\n",
    "frames = read_and_preprocess_video(\n",
    "    VIDEO_FILE_PATH,\n",
    "    target_num_frames=NUM_FRAMES,\n",
    "    target_frame_size=[FRAME_SIZE, FRAME_SIZE],\n",
    ")\n",
    "mediapy.show_video(frames, fps=6.0)\n",
    "\n",
    "frames = jnp.asarray(frames[None, ...])  # Add batch dimension.\n",
    "if USE_BFLOAT16:\n",
    "  frames = frames.astype(jnp.bfloat16)\n",
    "print(f'Input shape: {frames.shape} [type: {frames.dtype}]')\n",
    "\n",
    "embeddings, _ = forward_fn(frames)\n",
    "print(f'Encoded embedding shape: {embeddings.shape} [type: {embeddings.dtype}]')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
